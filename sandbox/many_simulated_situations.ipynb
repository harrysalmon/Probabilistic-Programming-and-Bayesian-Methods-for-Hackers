{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import scipy.stats\n",
    "from statsmodels.stats import weightstats\n",
    "import matplotlib.mlab as mlab\n",
    "from pymc.Matplot import plot as mcplot\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## transfer some data into a form we can work with\n",
    "class Sample:\n",
    "    def __init__(self, samples, mean):\n",
    "        self.samples = int(samples)\n",
    "        self.mean = mean\n",
    "        self.successes = int(round(samples * mean))\n",
    "        self.failures = int(round(samples * (1-mean)))\n",
    "        self.observations = np.array([0]*self.failures + [1]*self.successes)\n",
    "        np.random.shuffle(self.observations)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Sample: samples={samples:d}, mean={mean:.3f}\".format(samples=self.samples, mean=self.mean)\n",
    "    def __unicode__(self):\n",
    "        return \"Sample: samples={samples:d}, mean={mean:.3f}\".format(samples=self.samples, mean=self.mean)\n",
    "    def __repr__(self):\n",
    "        return \"Sample: samples={samples:d}, mean={mean:.3f}\".format(samples=self.samples, mean=self.mean)\n",
    "        \n",
    "    @classmethod\n",
    "    def from_success_failure(self, successes, failures):\n",
    "        self.samples = successes + failures\n",
    "        self.successes = successes\n",
    "        self.failures = failures\n",
    "        self.observations = np.array([0]*self.failures + [1]*self.successes)\n",
    "        np.random.shuffle(self.observations) # inplace\n",
    "        self.mean = np.mean(self.observations)\n",
    "        \n",
    "class BaysianSummary:\n",
    "    def __init__(self, trace):\n",
    "        self.trace = trace\n",
    "        self.data = trace[:]\n",
    "        self.posterior_mean = self.data.mean()\n",
    "        self.posterior_5th  = np.percentile(self.data, 5)\n",
    "        self.posterior_95th  = np.percentile(self.data, 95)\n",
    "        self.p_better_than = (self.data < 0).mean()\n",
    "        self.p_worse_than = (self.data > 0).mean()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"BaysianSummary: posterior_mean=%.3f\" % (self.posterior_mean,)\n",
    "    def __unicode__(self):\n",
    "        return \"BaysianSummary: posterior_mean=%.3f\" % (self.posterior_mean,)\n",
    "    def __repr__(self):\n",
    "        return \"BaysianSummary: posterior_mean=%.3f\" % (self.posterior_mean,)\n",
    "    \n",
    "        \n",
    "class FrequentistSummary:\n",
    "    def __init__(self, delta, p):\n",
    "        self.delta = delta\n",
    "        self.p = p\n",
    "        self.sig = p < 0.05\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"FrequentistSummary: delta=%.3f\" % (self.delta,)\n",
    "    def __unicode__(self):\n",
    "        return \"FrequentistSummary: delta=%.3f\" % (self.delta,)\n",
    "    def __repr__(self):\n",
    "        return \"FrequentistSummary: delta=%.3f\" % (self.delta,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the pymc model. Again assume Uniform priors for p_A and p_B.\n",
    "def run_bayes(sample1, sample2):\n",
    "\n",
    "    p_A = pm.Uniform(\"p_A\", 0, 1)\n",
    "    p_B = pm.Uniform(\"p_B\", 0, 1)\n",
    "\n",
    "\n",
    "    # Define the deterministic delta function. This is our unknown of interest.\n",
    "    @pm.deterministic\n",
    "    def delta(p_A=p_A, p_B=p_B):\n",
    "        return p_A - p_B\n",
    "\n",
    "    # Set of observations, in this case we have two observation datasets.\n",
    "    obs_A = pm.Bernoulli(\"obs_A\", p_A, value=sample1.observations, observed=True)\n",
    "    obs_B = pm.Bernoulli(\"obs_B\", p_B, value=sample2.observations, observed=True)\n",
    "\n",
    "    model = pm.Model([p_A, p_B, delta, obs_A, obs_B])\n",
    "    map_ = pm.MAP(model)\n",
    "    map_.fit()\n",
    "    mcmc = pm.MCMC(model)\n",
    "    mcmc.sample(20000, 1000)\n",
    "    \n",
    "    return mcmc.trace(\"delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frequentist_from_samples(sample1, sample2):\n",
    "    mu1 = sample1.observations.mean()\n",
    "    mu2 = sample2.observations.mean()\n",
    "    SE1 = mu1 * (1-mu1) / math.sqrt(len(sample1.observations))\n",
    "    SE2 = mu2 * (1-mu2) / math.sqrt(len(sample2.observations))\n",
    "    z = (mu1 - mu2) / (SE1**2 + SE2**2)**0.5\n",
    "    p = scipy.stats.norm.sf(abs(z))*2\n",
    "    delta = mu1 - mu2\n",
    "    return FrequentistSummary(delta, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Sample: samples=10000, mean=0.031, Sample: samples=10000, mean=0.030),\n",
       " (Sample: samples=1000, mean=0.033, Sample: samples=1000, mean=0.030),\n",
       " (Sample: samples=10000, mean=0.033, Sample: samples=10000, mean=0.030),\n",
       " (Sample: samples=1000, mean=0.103, Sample: samples=1000, mean=0.100),\n",
       " (Sample: samples=10000, mean=0.103, Sample: samples=10000, mean=0.100),\n",
       " (Sample: samples=100, mean=0.110, Sample: samples=100, mean=0.100),\n",
       " (Sample: samples=1000, mean=0.110, Sample: samples=1000, mean=0.100),\n",
       " (Sample: samples=10000, mean=0.110, Sample: samples=10000, mean=0.100)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# control_means = [0.003, 0.01, 0.03, 0.1, 0.3]\n",
    "# proportional_differences = [0.01, 0.03, 0.1, 0.2]\n",
    "# n_samples = [100, 1000, 10000, 100000, 1000000]\n",
    "\n",
    "control_means = [0.03, 0.1]\n",
    "proportional_differences = [0.03, 0.1]\n",
    "n_samples = [100, 1000, 10000]\n",
    "samples_means = [(muC, muC*(1+propdiff)) \n",
    "                 for muC in control_means \n",
    "                 for propdiff in proportional_differences]\n",
    "\n",
    "sample_pairs = [(Sample(samples, muV), Sample(samples, muC))\n",
    "                for (muC, muV) in samples_means\n",
    "                for samples in n_samples\n",
    "               if abs(muV-muC)*samples >= 1] # so that the control and variant are actually different\n",
    "\n",
    "sample_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [----------       27%                  ] 5411 of 20000 complete in 4.0 sec"
     ]
    }
   ],
   "source": [
    "outputs = [(BaysianSummary(run_bayes(sample1, sample2)), frequentist_from_samples(sample1, sample2)) \n",
    "           for (sample1, sample2) in sample_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[(bayes.posterior_mean,freq.delta) \n",
    " for (bayes, freq) in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_for_csv = [(b.posterior_5th, b.posterior_mean, b.posterior_95th, f.delta, f.sig) for (b,f) in outputs]\n",
    "output_for_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"/home/harry/Documents/many_sumulated_situations.csv\", \"w\") as the_file:\n",
    "    writer = csv.writer(the_file, delimiter=',')\n",
    "    writer.writerow([\"b.posterior_5th\", \"b.posterior_mean\", \"b.posterior_95th\", \"f.delta\", \"f.sig\"])\n",
    "    writer.writerows(output_for_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcplot(outputs[0][0].trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
